{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Di-Tech Challenge\n",
    "\n",
    "## Description \n",
    "\n",
    "As less than 10% of China’s 1.4 billion citizens own automobiles, the frequency at which Chinese citizens commute on taxis, buses, trains, and planes is the highest in the world. Didi Chuxing, the dominant ride-hailing company in China, processes over 11 million trips, plans over 9 billion routes and collects over 50TB of data per day. To meet needs of riders, Didi must continually innovate to improve cloud computing and big data technologies and algorithms in order to process this massive amount of data and uphold service reliability.\n",
    "Supply-demand forecasting is critical to enabling Didi to maximise utilisation of drivers and ensure that riders can always get a car whenever and wherever they may need a ride. Supply-demand forecasting helps to predict the volume of drivers and riders at a certain time period in a specific geographic area. For instance, demand tends to surge in residential areas in the mornings and in business districts in the evenings. Supply-demand forecasting allows Didi to predict demand surges and guide drivers to those areas. The end result is higher earnings for drivers and no surge pricing for riders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "path = '/Didi_competition/training_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order\n",
    "\n",
    "The Order Info Table shows the basic information of an order, including the passenger and the driver (if driver_id =NULL, it means the order was not answered by any driver), place of origin, destination, price and time. The fields order_id, driver_id, passenger_id, start_hash, and dest_hash are made not sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_order = path + 'order_data/order_data_2016-01-'\n",
    "\n",
    "header_order = ['order_id','driver_id','passenger_id','start_district_hash',\n",
    "                  'dest_district_hash', 'Price', 'Time']\n",
    "                  \n",
    "list_df_order = [pd.read_csv(path_order + str(i).zfill(2), delimiter='\\t', \n",
    "                          header=None, names = header_order) for i in xrange(1,4)]\n",
    "\n",
    "df_order = pd.concat(list_df_order)\n",
    "df_order.shape\n",
    "df_order.describe\n",
    "df_order.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Jam\n",
    "\n",
    "The Traffic Jam Info Table shows the overall traffic status on the road in a district, including the number of roads at different traffic jam levels in different time periods and different districts. Higher values mean heavier traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_traffic = path + 'traffic_data/traffic_data_2016-01-'\n",
    "\n",
    "header_traffic = ['district_hash','tj_level_1','tj_level_2','tj_level_3',\n",
    "                  'tj_level_4', 'tj_time']\n",
    "\n",
    "list_df_traffic = [pd.read_csv(path_traffic + str(i).zfill(2), delimiter='\\t', \n",
    "                          header=None, names = header_traffic) for i in xrange(1,4)]\n",
    "\n",
    "df_traffic = pd.concat(list_df_traffic)\n",
    "df_traffic.shape\n",
    "df_traffic.describe()\n",
    "df_traffic.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data\n",
    "\n",
    "The Weather Info Table shows the weather info every 10 minutes each city. The weather field gives the weather conditions such as sunny, rainy, and snowy etc; all sensitive information has been removed. The unit of temperature is Celsius degree, and PM2.5 is the level of air pollutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weather = path + 'weather_data/weather_data_2016-01-'\n",
    "\n",
    "header_weather = ['Time','Weather','temperature','PM2.5']\n",
    "\n",
    "list_df_weather = [pd.read_csv(path_weather + str(i).zfill(2), delimiter='\\t', \n",
    "                          header=None, names = header_weather) for i in xrange(1,4)]\n",
    "\n",
    "df_weather = pd.concat(list_df_weather)\n",
    "df_weather.shape\n",
    "df_weather.describe\n",
    "df_weather.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  District\n",
    "\n",
    "The District Info Table shows the information about the districts to be evaluated in the contest. You need to do the prediction given the districts from the District Definition Table. In the submission of the results, you need to map the district hash value to district mapped ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_district = path + 'cluster_map/cluster_map'\n",
    "\n",
    "header_district = ['district_hash','district_id']\n",
    "\n",
    "df_district = pd.read_csv(path_district, delimiter='\\t', header=None, names = header_district)\n",
    "df_district.describe()\n",
    "df_district.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POI\n",
    "\n",
    "The POI Info Table shows the attributes of a district, such as the number of different facilities. For example, 2#1:22 means in this district, there are 22 facilities of the facility class 2#1. 2#1 means the first level class is 2 and the second level is 1, such as entertainment#theater, shopping#home appliance, sports#others. Each class and its number is separated by \\t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_POI = path + 'poi_data/poi_data'\n",
    "\n",
    "header_POI_temp = ['poi']\n",
    "\n",
    "df_POI_temp = pd.read_csv(path_POI, delimiter='\\n', header=None, names = header_POI_temp)\n",
    "\n",
    "list_POI = df_POI_temp['poi'].str.split('\\t').tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_POI =[['74c1c25f4b283fa74a5514307b0d0278','1#11:2241','1#10:249','24:1245', ... ],\n",
    "           ['99c25f4b283fa74a5514307b0d02767h8','20:33449','22:2324','15#24:833', ...],\n",
    "            ....]`\n",
    "            \n",
    "There are 66 disctricts. 26 first level and 26 second level classes.            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_list = []\n",
    "for j in range(66):                \n",
    "  rec_list =[]\n",
    "  first_n =[]\n",
    "  second_n = []\n",
    "  for i in list_POI[j][1:-1]:\n",
    "    if '#' in i:\n",
    "        minilist = map(int, i.replace(':','#').split('#'))\n",
    "        rec_list.append(minilist)\n",
    "    else:\n",
    "        minilist = map(int, ['0']+i.split(':'))\n",
    "        rec_list.append(minilist) \n",
    "    first_n.append(minilist[0])\n",
    "    second_n.append(minilist[1])             \n",
    "  complete_list.append(rec_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "for i in list_POI:\n",
    "    ids.append(i[0])\n",
    "\n",
    "my_dict = {}\n",
    "for i in range(676):\n",
    "  my_dict[i+1] = [0]*66\n",
    "\n",
    "# create empty dataframe - discrict_hash as indices\n",
    "df_POI = pd.DataFrame(my_dict,index=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entries = []\n",
    "for i in range(66):\n",
    "     count = 0\n",
    "     for j in range(676):\n",
    "         for triplet in complete_list[i]:             \n",
    "             if triplet[0] == int(floor(j/26)) and triplet[1] == j%26:\n",
    "                 df_POI[j][i] = triplet[2]\n",
    "                 #print triplet\n",
    "                 count = count + 1               \n",
    "     n_entries.append(count)\n",
    "\n",
    "df_POI.head(5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notation is the following:\n",
    "\n",
    "12:234  interpreted as 0#12:234.\n",
    "\n",
    "1 = 0#1, 2 = 0#2, 3 = 0#3, ...\n",
    "\n",
    "26=0#26, 27 = 1#1, 28 = 1#2, 29 = 1#3, ...\n",
    "\n",
    "53 = 2#1, 54 = 2#2, ...\n",
    "\n",
    "....\n",
    "\n",
    "..., 676 = 25#26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a test to confirm that it's ok\n",
    "n_ele = []\n",
    "for ele in complete_list:\n",
    "    n_ele.append(len(ele))\n",
    "\n",
    "array(n_entries)-array(n_ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some data\n",
    "\n",
    "\n",
    "There are \n",
    "\n",
    "Total orders: 8,540,614 (first 3 days 1,148,684)  \n",
    "Unique passengers: 1,368,071 (471,999)  \n",
    "Unique drivers: 93,090 (49,249)  \n",
    "Duplicate orders: 22,565 [0.26%]  (5,506 [0.48%])  \n",
    "Orders per passanger: 6.24 (2.43)  \n",
    "Orders per driver: 91.75 (23.3)  \n",
    "\n",
    "\n",
    "Orders/day: 406,696 (382,895)\n",
    "\n",
    "\n",
    "Price  \n",
    "mean          17.32  \n",
    "std         16.16  \n",
    "min          0.0  \n",
    "25%          8.0  \n",
    "50%         13.0  \n",
    "75%         21.0  \n",
    "max       1731.0  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order[df_order['order_id'] == 'ee99387a4c9abe0698a1c44771ad6b76']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order[df_order['order_id'] == 'ef2fb75c5b051095ea6a440cc5019248']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many rows per order_id and driver_id\n",
    "count = df_order[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = count['driver_id']\n",
    "\n",
    "number_no_picks = sum(count == 0)\n",
    "number_picks = sum(count == 1)\n",
    "number_orders = len(count)\n",
    "\n",
    "print number_no_picks\n",
    "print number_picks\n",
    "percentage_no_picks = number_no_picks/number_orders*100\n",
    "\n",
    "\n",
    "print(\"There are {} orders-without-drivers out of {} orders: {}.\".format(number_no_picks, number_orders, percentage_no_picks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = count['driver_id']\n",
    "\n",
    "# Orders picked up by more than one driver?\n",
    "print(sum(count > 1))\n",
    "# No more.\n",
    "\n",
    "# Create gap column\n",
    "gap = (count == 0).astype('int').tolist()\n",
    "#df_order['gap'] = gap\n",
    "\n",
    "#print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count = count['driver_id']\n",
    "\n",
    "# Proportion of orders not picked up by a driver\n",
    "s = sum(count == 0)\n",
    "l = len(count)\n",
    "\n",
    "print(\"There are {} orders-without-drivers out of {} orders: {:.1%}.\".format(s, l, s/l))\n",
    "# It appears the gap is simply the number of orders not picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count = count['driver_id']\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.isnull(df).any(1).nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = df.duplicated(['order_id', 'driver_id', 'passenger_id', 'Time'], keep = 'last')\n",
    "df = df[~dup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gap column\n",
    "gap = (count == 0).astype('int').tolist()\n",
    "df['gap'] = gap\n",
    "\n",
    "#print(df.describe())\n",
    "\n",
    "#df.drop_duplicates(['order_id', 'driver_id', 'passenger_id', 'time'], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute time slot\n",
    "\n",
    "# Extract the date, and implicitly make the time midnight.\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "df['date'] = pd.to_datetime(df.Time.dt.date)\n",
    "# df['timeonly'] = df.datetime.dt.time\n",
    "\n",
    "# One day is uniformly divided into 144 ten minute time slots.\n",
    "df['timeslot'] = (df['Time'] - df['date']).astype('timedelta64[m]')//10\n",
    "\n",
    "# Drop the time column\n",
    "# df = df.drop('time', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gap per time slot per district\n",
    "df_select = df[['start_district_hash', 'date', 'timeslot', 'gap']]\n",
    "df_gap = df_select.groupby(['start_district_hash', 'date', 'timeslot']).sum()\n",
    "\n",
    "# Flatten data frame after the group by\n",
    "df_gap = df_gap.reset_index()\n",
    "print(df_gap.head(2))\n",
    "\n",
    "# Sanity check: do the numbers add up?\n",
    "print(sum(df_gap.gap))\n",
    "# Yup.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_time = df_gap.groupby(['date', 'timeslot']).sum()\n",
    "df_gap_time.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headsize = 800\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.plot(df_gap_time['gap'].head(headsize), color='r', alpha=0.5)    \n",
    "#rects2 = ax.plot(df['EXITSn_hourly'  ].head(headsize), color='b', alpha=0.5)    \n",
    "#plt.ylabel('ENTRIES / EXITS')\n",
    "ax.set_yscale('log')   \n",
    "plt.grid(True)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enricofonda/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "##### MAPE\n",
    "\n",
    "def mape(y_true,y_pred):\n",
    "    idx = y_true != 0\n",
    "    return np.mean(np.abs((y_true[idx] - y_pred[idx]) / y_true[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_hash</th>\n",
       "      <th>date</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>gap</th>\n",
       "      <th>counter</th>\n",
       "      <th>weekday</th>\n",
       "      <th>district_id</th>\n",
       "      <th>Weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>PM</th>\n",
       "      <th>tj_level_1</th>\n",
       "      <th>tj_level_2</th>\n",
       "      <th>tj_level_3</th>\n",
       "      <th>tj_level_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177</td>\n",
       "      <td>104</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      district_hash       date  timeslot  gap  counter  \\\n",
       "0  08232402614a9b48895cc3d0aeb0e9f2 2016-01-01       6.0    2        4   \n",
       "1  08232402614a9b48895cc3d0aeb0e9f2 2016-01-01       7.0    1        1   \n",
       "2  08232402614a9b48895cc3d0aeb0e9f2 2016-01-01       8.0    0        1   \n",
       "3  08232402614a9b48895cc3d0aeb0e9f2 2016-01-01      14.0    0        1   \n",
       "4  08232402614a9b48895cc3d0aeb0e9f2 2016-01-01      15.0    1        1   \n",
       "\n",
       "   weekday  district_id  Weather  temperature   PM  tj_level_1  tj_level_2  \\\n",
       "0        4           50        1          3.0  177         114           2   \n",
       "1        4           50        1          3.0  177          82          17   \n",
       "2        4           50        1          3.0  177         104          24   \n",
       "3        4           50        1          3.0  206          92           3   \n",
       "4        4           50        1          3.0  206          93           6   \n",
       "\n",
       "   tj_level_3  tj_level_4  \n",
       "0           1           0  \n",
       "1          10           1  \n",
       "2           2          14  \n",
       "3           0           0  \n",
       "4           4           9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Didi_competition/season_2/training_data/'\n",
    "file_name = 'df_didi_noPOI_mergedleft.pkl'\n",
    "file_name = 'df_didi_noPOI.pkl'\n",
    "#df.to_pickle(path + file_name)\n",
    "df = pd.read_pickle(path + file_name)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['timeslot_before'] = df.groupby(['district_id','date']).shift(1).timeslot\n",
    "df['gap_before'] = df.groupby(['district_id','date']).shift(1).gap\n",
    "df['counter_before'] = df.groupby(['district_id','date']).shift(1).counter\n",
    "\n",
    "df['timeslot_before2'] = df.groupby(['district_id','date']).shift(2).timeslot\n",
    "df['gap_before2'] = df.groupby(['district_id','date']).shift(2).gap\n",
    "df['counter_before2'] = df.groupby(['district_id','date']).shift(2).counter\n",
    "df['timeslot_before3'] = df.groupby(['district_id','date']).shift(3).timeslot\n",
    "df['gap_before3'] = df.groupby(['district_id','date']).shift(3).gap\n",
    "df['counter_before3'] = df.groupby(['district_id','date']).shift(3).counter\n",
    "\n",
    "df['delta_timeslot'] = df['timeslot']-df['timeslot_before']\n",
    "df['delta_timeslot2'] = df['timeslot_before']-df['timeslot_before2']\n",
    "df['delta_timeslot3'] = df['timeslot_before2']-df['timeslot_before3']\n",
    "\n",
    "df['tj_1_before'] = df.groupby(['district_id','date']).shift(1).tj_level_1\n",
    "df['tj_2_before'] = df.groupby(['district_id','date']).shift(1).tj_level_2\n",
    "df['tj_3_before'] = df.groupby(['district_id','date']).shift(1).tj_level_3\n",
    "df['tj_4_before'] = df.groupby(['district_id','date']).shift(1).tj_level_4\n",
    "\n",
    "df['Weather_before'] = df.groupby(['district_id','date']).shift(1).Weather\n",
    "df['temperature_before'] = df.groupby(['district_id','date']).shift(1).temperature\n",
    "df['PM_before'] = df.groupby(['district_id','date']).shift(1).PM\n",
    "\n",
    "\n",
    "#df['Weather_before'].value_counts()\n",
    "#df['Weather'].value_counts()\n",
    "#df['Weather_before'] = 'W_' + df['Weather_before'].astype(int).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139582, 33)\n",
      "138217\n",
      "138217\n",
      "(138217, 33)\n"
     ]
    }
   ],
   "source": [
    "# Deal with NaNs\n",
    "print df.shape\n",
    "df = df[np.isfinite(df['timeslot_before'])] # remove NaN rows\n",
    "df.temperature_before = df.temperature_before.fillna(method='backfill')\n",
    "df.Weather_before = df.Weather_before.fillna(method='backfill')\n",
    "print len(df[np.isfinite(df['tj_1_before'])])\n",
    "print len(df[np.isfinite(df['Weather_before'])])\n",
    "#df = df[np.isfinite(df['tj_1_before'])]\n",
    "#df = df[np.isfinite(df['Weather_before'])]\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45087, 30)\n"
     ]
    }
   ],
   "source": [
    "df=df[df['delta_timeslot'].isin([1.0])]\n",
    "df=df[df['delta_timeslot2'].isin([1.0])]\n",
    "df=df[df['delta_timeslot3'].isin([1.0])]\n",
    "df = df.drop('delta_timeslot', 1)\n",
    "df = df.drop('delta_timeslot2', 1)\n",
    "df = df.drop('delta_timeslot3', 1)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_hash</th>\n",
       "      <th>date</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>gap</th>\n",
       "      <th>counter</th>\n",
       "      <th>weekday</th>\n",
       "      <th>district_id</th>\n",
       "      <th>Weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>PM</th>\n",
       "      <th>...</th>\n",
       "      <th>timeslot_before3</th>\n",
       "      <th>gap_before3</th>\n",
       "      <th>counter_before3</th>\n",
       "      <th>tj_1_before</th>\n",
       "      <th>tj_2_before</th>\n",
       "      <th>tj_3_before</th>\n",
       "      <th>tj_4_before</th>\n",
       "      <th>Weather_before</th>\n",
       "      <th>temperature_before</th>\n",
       "      <th>PM_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72997</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72998</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73002</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73003</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73004</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          district_hash       date  timeslot  gap  counter  \\\n",
       "72997  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        12    3       73   \n",
       "72998  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        13    1       60   \n",
       "73002  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        20    6       46   \n",
       "73003  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        21    2       41   \n",
       "73004  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        22    1       32   \n",
       "\n",
       "       weekday  district_id  Weather  temperature   PM    ...      \\\n",
       "72997        4            1        1          3.0  206    ...       \n",
       "72998        4            1        1          3.0  206    ...       \n",
       "73002        4            1        1          3.0  205    ...       \n",
       "73003        4            1        1          3.0  205    ...       \n",
       "73004        4            1        1          3.0  205    ...       \n",
       "\n",
       "       timeslot_before3  gap_before3  counter_before3  tj_1_before  \\\n",
       "72997               9.0          6.0            120.0       1316.0   \n",
       "72998              10.0          6.0            111.0       1393.0   \n",
       "73002              17.0         20.0             73.0       1211.0   \n",
       "73003              18.0         18.0             65.0       1160.0   \n",
       "73004              19.0         11.0             60.0       1165.0   \n",
       "\n",
       "       tj_2_before  tj_3_before  tj_4_before  Weather_before  \\\n",
       "72997        241.0         82.0         64.0             1.0   \n",
       "72998        254.0         65.0         65.0             1.0   \n",
       "73002        143.0         54.0         51.0             1.0   \n",
       "73003        163.0         39.0         51.0             1.0   \n",
       "73004        153.0         48.0         51.0             1.0   \n",
       "\n",
       "       temperature_before  PM_before  \n",
       "72997                 3.0      206.0  \n",
       "72998                 3.0      206.0  \n",
       "73002                 3.0      205.0  \n",
       "73003                 3.0      205.0  \n",
       "73004                 3.0      205.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timeslot'] = df['timeslot'].astype(int)\n",
    "df = df.sort_values(['district_id','date','timeslot'], ascending=[True,True,True])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_hash</th>\n",
       "      <th>date</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>gap</th>\n",
       "      <th>counter</th>\n",
       "      <th>weekday</th>\n",
       "      <th>district_id</th>\n",
       "      <th>Weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>PM</th>\n",
       "      <th>...</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72997</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72998</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73002</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73003</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73004</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          district_hash       date  timeslot  gap  counter  \\\n",
       "72997  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        12    3       73   \n",
       "72998  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        13    1       60   \n",
       "73002  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        20    6       46   \n",
       "73003  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        21    2       41   \n",
       "73004  90c5a34f06ac86aee0fd70e2adce7d8a 2016-01-01        22    1       32   \n",
       "\n",
       "       weekday  district_id  Weather  temperature   PM ...   day_2  day_3  \\\n",
       "72997        4            1        1          3.0  206 ...     0.0    0.0   \n",
       "72998        4            1        1          3.0  206 ...     0.0    0.0   \n",
       "73002        4            1        1          3.0  205 ...     0.0    0.0   \n",
       "73003        4            1        1          3.0  205 ...     0.0    0.0   \n",
       "73004        4            1        1          3.0  205 ...     0.0    0.0   \n",
       "\n",
       "       day_4  day_5  day_6  1.0  2.0  3.0  4.0  8.0  \n",
       "72997    1.0    0.0    0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "72998    1.0    0.0    0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "73002    1.0    0.0    0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "73003    1.0    0.0    0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "73004    1.0    0.0    0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_district = pd.get_dummies('D_' + df['district_id'].astype(int).astype(str).apply(lambda x:x.zfill(2)))\n",
    "df = df.join(one_hot_district)\n",
    "df.head(50)\n",
    "\n",
    "\n",
    "one_hot_weekday = pd.get_dummies('day_' + df['weekday'].astype(int).astype(str))\n",
    "df = df.join(one_hot_weekday)\n",
    "df.head()\n",
    "# df = df.drop('day_1',1) - ####################\n",
    "#df = df.drop('day_3',1)\n",
    "\n",
    "one_hot_weather = pd.get_dummies(df['Weather_before'])\n",
    "df = df.join(one_hot_weather)\n",
    "# df.Weather.unique()\n",
    "df = df.drop(9.0,1) # drop because Weather 9 not present in the test set.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('district_hash',1)\n",
    "\n",
    "df = df.drop('tj_level_1',1)\n",
    "df = df.drop('tj_level_2',1)\n",
    "df = df.drop('tj_level_3',1)\n",
    "df = df.drop('tj_level_4',1)\n",
    "df = df.drop('PM',1)\n",
    "df = df.drop('temperature',1)\n",
    "df = df.drop('Weather',1)\n",
    "df = df.drop('counter',1)\n",
    "df = df.drop('timeslot_before',1)\n",
    "df = df.drop('timeslot_before2',1)\n",
    "df = df.drop('timeslot_before3',1)\n",
    "\n",
    "df = df.drop('PM_before',1)\n",
    "df = df.drop('Weather_before',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'timeslot',\n",
       " 'gap',\n",
       " 'weekday',\n",
       " 'district_id',\n",
       " 'gap_before',\n",
       " 'counter_before',\n",
       " 'gap_before2',\n",
       " 'counter_before2',\n",
       " 'gap_before3',\n",
       " 'counter_before3',\n",
       " 'tj_1_before',\n",
       " 'tj_2_before',\n",
       " 'tj_3_before',\n",
       " 'tj_4_before',\n",
       " 'temperature_before',\n",
       " 'D_01',\n",
       " 'D_02',\n",
       " 'D_03',\n",
       " 'D_04',\n",
       " 'D_05',\n",
       " 'D_06',\n",
       " 'D_07',\n",
       " 'D_08',\n",
       " 'D_09',\n",
       " 'D_10',\n",
       " 'D_11',\n",
       " 'D_12',\n",
       " 'D_13',\n",
       " 'D_14',\n",
       " 'D_15',\n",
       " 'D_16',\n",
       " 'D_17',\n",
       " 'D_18',\n",
       " 'D_19',\n",
       " 'D_20',\n",
       " 'D_21',\n",
       " 'D_22',\n",
       " 'D_23',\n",
       " 'D_24',\n",
       " 'D_25',\n",
       " 'D_26',\n",
       " 'D_27',\n",
       " 'D_28',\n",
       " 'D_29',\n",
       " 'D_30',\n",
       " 'D_31',\n",
       " 'D_32',\n",
       " 'D_33',\n",
       " 'D_34',\n",
       " 'D_35',\n",
       " 'D_36',\n",
       " 'D_37',\n",
       " 'D_38',\n",
       " 'D_39',\n",
       " 'D_40',\n",
       " 'D_41',\n",
       " 'D_42',\n",
       " 'D_43',\n",
       " 'D_44',\n",
       " 'D_45',\n",
       " 'D_46',\n",
       " 'D_47',\n",
       " 'D_48',\n",
       " 'D_49',\n",
       " 'D_50',\n",
       " 'D_51',\n",
       " 'D_52',\n",
       " 'D_53',\n",
       " 'D_55',\n",
       " 'D_56',\n",
       " 'D_57',\n",
       " 'D_58',\n",
       " 'D_59',\n",
       " 'D_60',\n",
       " 'D_61',\n",
       " 'D_62',\n",
       " 'D_63',\n",
       " 'D_64',\n",
       " 'D_65',\n",
       " 'D_66',\n",
       " 'day_0',\n",
       " 'day_1',\n",
       " 'day_2',\n",
       " 'day_3',\n",
       " 'day_4',\n",
       " 'day_5',\n",
       " 'day_6',\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 8.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(df.columns.tolist())\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## -- Create training and test set, as two week and 1 week\n",
    "# if training on full 3 weks: train_variables = df\n",
    "mask = (df['date'] >= '2016-01-01') & (df['date'] <= '2016-01-14')\n",
    "#mask_first_week = (df['date'] >= '2016-01-01') & (df['date'] <= '2016-01-07')\n",
    "train_variables = df.loc[mask]\n",
    "test_variables = df.loc[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36276, 89)\n"
     ]
    }
   ],
   "source": [
    "labels_train = train_variables[['gap']].as_matrix().astype(int)            \n",
    "#labels_train_orders = train_variables[['counter']].as_matrix().astype(int) \n",
    "\n",
    "train_variables = train_variables.drop('date',1)\n",
    "train_variables = train_variables.drop('district_id',1)\n",
    "train_variables = train_variables.drop('gap',1)\n",
    "train_variables = train_variables.drop('weekday',1)\n",
    "\n",
    "\n",
    "features_train = train_variables.as_matrix().astype(int)\n",
    "print np.shape(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timeslot',\n",
       " 'gap_before',\n",
       " 'counter_before',\n",
       " 'gap_before2',\n",
       " 'counter_before2',\n",
       " 'gap_before3',\n",
       " 'counter_before3',\n",
       " 'tj_1_before',\n",
       " 'tj_2_before',\n",
       " 'tj_3_before',\n",
       " 'tj_4_before',\n",
       " 'temperature_before',\n",
       " 'D_01',\n",
       " 'D_02',\n",
       " 'D_03',\n",
       " 'D_04',\n",
       " 'D_05',\n",
       " 'D_06',\n",
       " 'D_07',\n",
       " 'D_08',\n",
       " 'D_09',\n",
       " 'D_10',\n",
       " 'D_11',\n",
       " 'D_12',\n",
       " 'D_13',\n",
       " 'D_14',\n",
       " 'D_15',\n",
       " 'D_16',\n",
       " 'D_17',\n",
       " 'D_18',\n",
       " 'D_19',\n",
       " 'D_20',\n",
       " 'D_21',\n",
       " 'D_22',\n",
       " 'D_23',\n",
       " 'D_24',\n",
       " 'D_25',\n",
       " 'D_26',\n",
       " 'D_27',\n",
       " 'D_28',\n",
       " 'D_29',\n",
       " 'D_30',\n",
       " 'D_31',\n",
       " 'D_32',\n",
       " 'D_33',\n",
       " 'D_34',\n",
       " 'D_35',\n",
       " 'D_36',\n",
       " 'D_37',\n",
       " 'D_38',\n",
       " 'D_39',\n",
       " 'D_40',\n",
       " 'D_41',\n",
       " 'D_42',\n",
       " 'D_43',\n",
       " 'D_44',\n",
       " 'D_45',\n",
       " 'D_46',\n",
       " 'D_47',\n",
       " 'D_48',\n",
       " 'D_49',\n",
       " 'D_50',\n",
       " 'D_51',\n",
       " 'D_52',\n",
       " 'D_53',\n",
       " 'D_55',\n",
       " 'D_56',\n",
       " 'D_57',\n",
       " 'D_58',\n",
       " 'D_59',\n",
       " 'D_60',\n",
       " 'D_61',\n",
       " 'D_62',\n",
       " 'D_63',\n",
       " 'D_64',\n",
       " 'D_65',\n",
       " 'D_66',\n",
       " 'day_0',\n",
       " 'day_1',\n",
       " 'day_2',\n",
       " 'day_3',\n",
       " 'day_4',\n",
       " 'day_5',\n",
       " 'day_6',\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 8.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_variables.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variables = test_variables[test_variables['weekday'].isin([0,2,4,5,6])]\n",
    "test_variables = test_variables[test_variables['timeslot'].isin([46,58,70,82,94,106,118,130,142])]\n",
    "\n",
    "results_val = (test_variables['district_id'].astype(str)).reset_index().drop('index',1)\n",
    "results_val['datetime'] = (test_variables['date'].astype(str) +'-'+ test_variables['timeslot']\n",
    "                  .astype(int).astype(str)).reset_index().drop('index',1)\n",
    " \n",
    "results_val['gap_outcome'] = test_variables['gap'].reset_index().drop('index',1)\n",
    "                      \n",
    "\n",
    "labels_test = test_variables['gap'].as_matrix().astype(int)\n",
    "\n",
    "test_variables = test_variables.drop('date',1)\n",
    "test_variables = test_variables.drop('district_id',1)\n",
    "test_variables = test_variables.drop('gap',1)\n",
    "test_variables = test_variables.drop('weekday',1)\n",
    "\n",
    "test_variables.columns.tolist()\n",
    "\n",
    "\n",
    "features_test = test_variables.as_matrix().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 89)\n"
     ]
    }
   ],
   "source": [
    "np.shape(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enricofonda/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 6.29 s\n",
      "MAPE: 0.49431\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "clf = GradientBoostingRegressor(n_estimators = 77)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "outcome = labels_test.flatten().astype(float)\n",
    "predict = pred.round().astype(float)#.astype(int)\n",
    "#predict = ceil(pred.astype(float))#.astype(int)\n",
    "\n",
    "score = mape(outcome, predict)\n",
    "print(\"MAPE: {:.5f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>gap_outcome</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-15-82</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-15-106</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-15-142</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-16-58</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-16-82</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district_id        datetime  gap_outcome  pred\n",
       "0           1   2016-01-15-82            5     8\n",
       "1           1  2016-01-15-106           12     8\n",
       "2           1  2016-01-15-142            2     3\n",
       "3           1   2016-01-16-58            4     4\n",
       "4           1   2016-01-16-82            2     4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = predict.astype(int)\n",
    "results_val['pred'] = predict_test\n",
    "results_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## - Save to file\n",
    "path_test = '/Didi_competition/season_2/test_set_2/'\n",
    "results_val.to_csv(path_test + 'predictions_one-hot-validation-previous.csv',index = False, header = False)\n",
    "\n",
    "#dict(zip(outcome.tolist(), predict.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_test = '/Didi_competition/season_2/test_set_2/'\n",
    "\n",
    "file_name = 'df_didi_test_season_2.pkl'\n",
    "#df.to_pickle(path_test + file_name)\n",
    "df_test = pd.read_pickle(path_test + file_name)\n",
    "df_test.head(300)\n",
    "\n",
    "df_test['date'] = df_test['date'].astype(str)\n",
    "\n",
    "df_test = df_test.sort_values(['district_id','date','timeslot'], ascending=[True,True,True])\n",
    "\n",
    "#df_test['Weather','temperature','PM','traffic','tj_level_1','tj_level_2',\n",
    "#        'tj_level_3','tj_level_4'] = df_test['Weather','temperature','PM',\n",
    "#        'traffic','tj_level_1','tj_level_2', 'tj_level_3','tj_level_4'\n",
    "#        ].fillna(method='backfill')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe with the dates and timeslots for which we need the predictions\n",
    "\n",
    "selected_dates = df_test['date'].unique().tolist()\n",
    "timeslots = ['46','58','70','82','94','106','118','130','142']\n",
    "\n",
    "df_temp = pd.DataFrame(list(product(range(1,67),selected_dates,timeslots)), columns=['district_id', 'date','timeslot'])\n",
    "\n",
    "df_temp['weekday'] = df_temp.date.apply(lambda x: datetime.strptime(x, '%Y-%m-%d').weekday())#\n",
    "\n",
    "idx1 =df_temp[(df_temp['date'] == '2016-01-25') & (df_temp['timeslot'] == '46')].index\n",
    "df_temp = df_temp.drop(idx1)\n",
    "idx2 =df_temp[(df_temp['date'] == '2016-01-29') & (df_temp['timeslot'] == '46')].index\n",
    "df_temp = df_temp.drop(idx2)\n",
    "\n",
    "df_temp['timeslot'] = df_temp['timeslot'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create new dataframe\n",
    "df_test= pd.merge(df_test, df_temp, on=['date','district_id','timeslot','weekday'], how='outer')\n",
    "df_test.drop('district_hash',1)\n",
    "\n",
    "df_test['timeslot'] = df_test['timeslot'].astype(int)\n",
    "df_test = df_test.sort_values(['district_id','date','timeslot'], ascending=[True,True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['gap_before'] = df_test.groupby(['district_id','date']).shift(1).gap\n",
    "df_test['counter_before'] = df_test.groupby(['district_id','date']).shift(1).counter\n",
    "\n",
    "df_test['gap_before2'] = df_test.groupby(['district_id','date']).shift(2).gap\n",
    "df_test['counter_before2'] = df_test.groupby(['district_id','date']).shift(2).counter\n",
    "df_test['gap_before3'] = df_test.groupby(['district_id','date']).shift(3).gap\n",
    "df_test['counter_before3'] = df_test.groupby(['district_id','date']).shift(3).counter\n",
    "\n",
    "df_test['tj_1_before'] = df_test.groupby(['district_id','date']).shift(1).tj_level_1\n",
    "df_test['tj_2_before'] = df_test.groupby(['district_id','date']).shift(1).tj_level_2\n",
    "df_test['tj_3_before'] = df_test.groupby(['district_id','date']).shift(1).tj_level_3\n",
    "df_test['tj_4_before'] = df_test.groupby(['district_id','date']).shift(1).tj_level_4\n",
    "\n",
    "df_test['Weather_before'] = df_test.groupby(['district_id','date']).shift(1).Weather\n",
    "df_test['temperature_before'] = df_test.groupby(['district_id','date']).shift(1).temperature\n",
    "df_test['PM_before'] = df_test.groupby(['district_id','date']).shift(1).PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "\n",
    "one_hot_district = pd.get_dummies('D_' + df_test['district_id'].astype(int).astype(str).apply(lambda x:x.zfill(2)))\n",
    "df_test = df_test.join(one_hot_district)\n",
    "# district_id dropped after merging\n",
    "\n",
    "one_hot_weekday = pd.get_dummies('day_' + df_test['weekday'].astype(int).astype(str))\n",
    "df_test = df_test.join(one_hot_weekday)\n",
    "# dropped dropped after merging\n",
    "\n",
    "one_hot_weather = pd.get_dummies(df_test['Weather_before'])\n",
    "df_test = df_test.join(one_hot_weather)\n",
    "df_test = df_test.drop(6.0,1) # dropped because not present in training set\n",
    "df_test = df_test.drop('Weather_before',1)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop('tj_level_1',1)\n",
    "df_test = df_test.drop('tj_level_2',1)\n",
    "df_test = df_test.drop('tj_level_3',1)\n",
    "df_test = df_test.drop('tj_level_4',1)\n",
    "df_test = df_test.drop('PM',1)\n",
    "df_test = df_test.drop('temperature',1)\n",
    "df_test = df_test.drop('Weather',1)\n",
    "#df_test = df_test.drop('timeslot_before',1)\n",
    "df_test = df_test.drop('district_hash',1)\n",
    "\n",
    "df_test = df_test.drop('PM_before',1)\n",
    "\n",
    "df_test.columns.tolist()\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop('counter',1)\n",
    "df_test = df_test.drop('gap',1)\n",
    "\n",
    "df_test= pd.merge(df_test, df_temp, on=['date','district_id','timeslot','weekday'], how='outer')\n",
    "\n",
    "df_test['weekday'] = df_test['weekday'].astype(int)\n",
    "df_test['district_id'] = df_test['district_id'].astype(int)\n",
    "\n",
    "# define new dataframe - merging \n",
    "test_test = pd.merge(df_test, df_temp, on=['date','district_id','timeslot','weekday'], how='inner')\n",
    "test_test = test_test.sort_values(['date','timeslot','district_id'], ascending=[True,True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = (test_test['district_id'].astype(str)).reset_index().drop('index',1)\n",
    "\n",
    "results['datetime'] = (test_test['date'].astype(str) +'-'+ test_test['timeslot']\n",
    "                  .astype(int).astype(str)).reset_index().drop('index',1)\n",
    "\n",
    "test_test = test_test.drop('date',1)\n",
    "test_test = test_test.drop('weekday',1)\n",
    "test_test = test_test.drop('district_id',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip (test_variables.columns.tolist(), test_test.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_test = test_test.as_matrix().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Predictions\n",
    "pred_test = clf.predict(features_test_test)\n",
    "predict_test = pred_test.round().astype(int)\n",
    "results['pred'] = predict_test\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## - Save to file\n",
    "path_test = '/Didi_competition/season_2/test_set_2/'\n",
    "results.to_csv(path_test + 'predictions-.csv',index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
